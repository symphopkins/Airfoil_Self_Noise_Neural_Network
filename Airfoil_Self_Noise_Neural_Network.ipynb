{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37926941",
   "metadata": {
    "id": "37926941"
   },
   "source": [
    "# DSCI 619: Project 1\n",
    "\n",
    "### Symphony Hopkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb89c2f",
   "metadata": {
    "id": "9fb89c2f"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a5820",
   "metadata": {
    "id": "e92a5820"
   },
   "source": [
    "For this project, we will be acting as a data scientist at NASA. We were given a data set obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections conducted in an anechoic wind tunnel.\n",
    "\n",
    "This dataset has the following features:\n",
    "\n",
    "* Frequency, in Hertzs.\n",
    "* Angle of attack, in degrees.\n",
    "* Chord length, in meters.\n",
    "* Free-stream velocity, in meters per second.\n",
    "* Suction side displacement thickness, in meters.\n",
    "\n",
    "The only target is:\n",
    "* Scaled sound pressure level, in decibels.\n",
    "\n",
    "Our objective is to create and evaluate deep learning regression models to forecast the scaled sound pressure level.\n",
    "\n",
    "\n",
    "Data Source: https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc7f5d",
   "metadata": {
    "id": "52dc7f5d"
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sY_WWsmNdi4l",
   "metadata": {
    "id": "sY_WWsmNdi4l"
   },
   "source": [
    "First, we will import the necessary libraries to load the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b70db",
   "metadata": {
    "id": "508b70db"
   },
   "source": [
    "**Q1. Load the dataset, airfoil_self_noise.DAT, into memory. \n",
    "(Hint: This file is tab separated file)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623039bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "623039bb",
    "outputId": "d43ebbf2-43f0-4970-a8ec-74c33fec6e73",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1       2     3         4        5\n",
       "0   800  0.0  0.3048  71.3  0.002663  126.201\n",
       "1  1000  0.0  0.3048  71.3  0.002663  125.201\n",
       "2  1250  0.0  0.3048  71.3  0.002663  125.951\n",
       "3  1600  0.0  0.3048  71.3  0.002663  127.591\n",
       "4  2000  0.0  0.3048  71.3  0.002663  127.461"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing library\n",
    "import pandas as pd\n",
    "\n",
    "#loading data\n",
    "df = pd.read_table('airfoil_self_noise.dat', sep = '\\t', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f0965",
   "metadata": {
    "id": "ad0f0965"
   },
   "source": [
    "**Q2. Clean the data and check missing values for this dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe02d48",
   "metadata": {
    "id": "cfe02d48"
   },
   "source": [
    "Looking at the data table, we can see that the column names are not assigned, so we will do that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ce9c42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "91ce9c42",
    "outputId": "8cfcf796-8828-4f52-bfeb-88baaaa5a2d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>angle</th>\n",
       "      <th>chord_len</th>\n",
       "      <th>fsv</th>\n",
       "      <th>ssdt</th>\n",
       "      <th>sspl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  angle  chord_len   fsv      ssdt     sspl\n",
       "0        800    0.0     0.3048  71.3  0.002663  126.201\n",
       "1       1000    0.0     0.3048  71.3  0.002663  125.201\n",
       "2       1250    0.0     0.3048  71.3  0.002663  125.951\n",
       "3       1600    0.0     0.3048  71.3  0.002663  127.591\n",
       "4       2000    0.0     0.3048  71.3  0.002663  127.461"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some column names were abbreviated\n",
    "df.columns = ['frequency','angle','chord_len','fsv','ssdt','sspl']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1776b",
   "metadata": {
    "id": "4ba1776b"
   },
   "source": [
    "Let's check the data types for each column to confirm they are in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f30f3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27f30f3c",
    "outputId": "c4312887-af89-418c-d021-980de9ebd859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frequency      int64\n",
       "angle        float64\n",
       "chord_len    float64\n",
       "fsv          float64\n",
       "ssdt         float64\n",
       "sspl         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7832caa",
   "metadata": {
    "id": "d7832caa"
   },
   "source": [
    "As we can see, the data in the columns are all numerical. Now, we will check each column to see if there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6485afc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6485afc8",
    "outputId": "9606d2e5-8360-491c-d9e2-dc8a78faecd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frequency    0\n",
       "angle        0\n",
       "chord_len    0\n",
       "fsv          0\n",
       "ssdt         0\n",
       "sspl         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8beb3",
   "metadata": {
    "id": "89c8beb3"
   },
   "source": [
    "We can confirm that there are not any missing values. The data is now prepared to be split into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d4867",
   "metadata": {
    "id": "b94d4867"
   },
   "source": [
    "**Q3. Split the data into 80% of training and 20% of test dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508c5e8a",
   "metadata": {
    "id": "508c5e8a"
   },
   "source": [
    "In order to split the data, we must assign the features into variable *X*, and assign the target into variable *y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063373b5",
   "metadata": {
    "id": "063373b5"
   },
   "outputs": [],
   "source": [
    "#assigning variables\n",
    "X = df.drop('sspl',axis=1)\n",
    "y = df['sspl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de621623",
   "metadata": {
    "id": "de621623"
   },
   "source": [
    "We will now split the data into training and test datasets with 80% going into the training dataset and 20% going into the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b64e620",
   "metadata": {
    "id": "2b64e620"
   },
   "outputs": [],
   "source": [
    "#splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34191e63",
   "metadata": {
    "id": "34191e63"
   },
   "source": [
    "For our first model, we will use simple linear regression from scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25172e7",
   "metadata": {
    "id": "e25172e7"
   },
   "source": [
    "**Q3. Build a simple linear regression to forecast \"Scaled sound pressure level\" using all other features and scikit-learn package. What's the test error for this scikit-learn regression model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acef4ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0acef4ee",
    "outputId": "96171319-6d07-4dee-9e86-21ada2ce1e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 25.00175595388133\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#creating linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "#training the model using the training dataset\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#making predictions using the test dataset\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "#computing the mean squared error to find the test error for the model\n",
    "print('Mean Squared Error (MSE):', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3c1e7",
   "metadata": {
    "id": "f8a3c1e7"
   },
   "source": [
    "MSE helps us determine if we have a good model. An MSE of 0 indicates that our model perfectly predicts values; however, it is important to note that this rarely, if ever, happens. For our test, we received a MSE of approximately 25, so there was a difference between the predicted values and actual values. The smaller the MSE, the better the model. We will create and evaluate more models to see if we can receive a better MSE.\n",
    "\n",
    "Source: https://en.wikipedia.org/wiki/Mean_squared_error#Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069db5ee",
   "metadata": {
    "id": "069db5ee"
   },
   "source": [
    "Because we have various features with different ranges, we need to normalize them so they can fall within the same range of [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9351ff2",
   "metadata": {
    "id": "f9351ff2"
   },
   "source": [
    "**Q4. Preprocess the data using the normalization method to convert all features into the range of [0,1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240b2d2e",
   "metadata": {
    "id": "240b2d2e"
   },
   "outputs": [],
   "source": [
    "#importing library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#creating a scaler so we can transform the data to fit within the range of [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#normalizing the data\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924abdc",
   "metadata": {
    "id": "0924abdc"
   },
   "source": [
    "Now that we have normalized the data, we can use it to create a deep learning regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b1132",
   "metadata": {
    "id": "404b1132"
   },
   "source": [
    "**Q5. Build a deep learning regression model to forecast \"Scaled sound pressure level\" using all other features and TensorFlow. Please use only two layers of neuron network. You choose the number of neurons to use in the first layer. What's the test error for this model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5922b15",
   "metadata": {
    "id": "b5922b15"
   },
   "source": [
    "To create a deep learning regression model, we must first import Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92467d8",
   "metadata": {
    "id": "f92467d8"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e0fb3",
   "metadata": {
    "id": "a02e0fb3"
   },
   "source": [
    "Now, we will set up the neural network. Since there are not set rules for determining the number of neurons in the first layer, we will set it to contain 6 neurons. The second layer will only contain 1 neuron because this is a regression problem and we need to aggregate all of the data from the previous layer into a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8642615f",
   "metadata": {
    "id": "8642615f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:00:53.082684: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-05 17:00:53.083341: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#setting up model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #first layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #second layer has 1 neuron\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71348b4c",
   "metadata": {
    "id": "71348b4c"
   },
   "source": [
    "Using the data we normalized earlier, we will train our new model. Since we are using Tensorflow, we must convert the data into numpy arrays first. Then, we can train the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d835f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5d835f9",
    "outputId": "b09532f0-652f-43f5-bfd6-bdc1c51b5386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:00:53.190165: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-05 17:00:53.377569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 12ms/step - loss: 15667.5332 - val_loss: 15559.1377\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15651.5400 - val_loss: 15543.4219\n",
      "Epoch 3/100\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 15667.2979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:00:53.921032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 15635.6846 - val_loss: 15527.6172\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15619.2676 - val_loss: 15510.7109\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15601.2275 - val_loss: 15491.3564\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15580.7402 - val_loss: 15468.9297\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15556.8701 - val_loss: 15442.4346\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15529.0010 - val_loss: 15410.8887\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15494.6416 - val_loss: 15370.5547\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15451.6855 - val_loss: 15320.9277\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15398.7598 - val_loss: 15260.7422\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15335.7168 - val_loss: 15190.0361\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15261.9316 - val_loss: 15109.2441\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15178.9531 - val_loss: 15022.1025\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15089.7637 - val_loss: 14931.0430\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14997.2910 - val_loss: 14837.3037\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14901.9834 - val_loss: 14740.3223\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14803.0410 - val_loss: 14640.6143\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14701.3555 - val_loss: 14536.8779\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14595.8584 - val_loss: 14429.9395\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14487.1211 - val_loss: 14319.4678\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14374.6387 - val_loss: 14206.0830\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14259.3486 - val_loss: 14089.0146\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14140.5322 - val_loss: 13968.7607\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14018.1689 - val_loss: 13846.0361\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 13893.5742 - val_loss: 13719.1797\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 13764.8701 - val_loss: 13589.9717\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13633.4131 - val_loss: 13457.2441\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13498.2871 - val_loss: 13320.5996\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13358.7832 - val_loss: 13179.0225\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 13214.2559 - val_loss: 13031.9873\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13063.5840 - val_loss: 12879.8271\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12907.9932 - val_loss: 12721.3008\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12746.2891 - val_loss: 12557.7354\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12579.9131 - val_loss: 12389.0938\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12408.2881 - val_loss: 12217.2393\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12233.6240 - val_loss: 12041.3467\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12055.0459 - val_loss: 11862.6318\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11874.3984 - val_loss: 11680.3154\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11690.1592 - val_loss: 11496.5732\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11504.5693 - val_loss: 11310.3311\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11316.4951 - val_loss: 11123.0283\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11127.2871 - val_loss: 10933.9600\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10936.6299 - val_loss: 10743.8398\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10744.7207 - val_loss: 10553.1084\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10552.3750 - val_loss: 10361.0107\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10358.9521 - val_loss: 10168.5830\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10165.4805 - val_loss: 9975.2119\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9970.8262 - val_loss: 9782.5830\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9776.5830 - val_loss: 9589.9111\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9582.5693 - val_loss: 9397.0996\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9388.4971 - val_loss: 9204.5850\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9194.8447 - val_loss: 9012.8535\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9001.9443 - val_loss: 8821.3809\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8809.4453 - val_loss: 8630.8398\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8618.1611 - val_loss: 8440.6807\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8427.2285 - val_loss: 8252.1592\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8237.8359 - val_loss: 8064.5454\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8049.2046 - val_loss: 7878.6909\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7862.4307 - val_loss: 7693.7559\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7676.7275 - val_loss: 7510.6353\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7492.8066 - val_loss: 7329.0938\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7310.6514 - val_loss: 7149.1392\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7130.1196 - val_loss: 6971.1338\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6951.5381 - val_loss: 6795.1245\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6774.8428 - val_loss: 6621.2949\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6600.2969 - val_loss: 6449.7495\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6428.2046 - val_loss: 6280.1602\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6258.1431 - val_loss: 6112.9297\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6090.4229 - val_loss: 5948.2456\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5925.2788 - val_loss: 5785.9673\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5762.4668 - val_loss: 5626.4854\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5602.5566 - val_loss: 5469.2275\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5444.8843 - val_loss: 5315.1655\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5290.2842 - val_loss: 5163.5708\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5138.2954 - val_loss: 5014.7422\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4989.0674 - val_loss: 4868.8105\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4842.6968 - val_loss: 4726.0103\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 4699.5112 - val_loss: 4585.8403\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4558.9355 - val_loss: 4448.8994\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4421.6587 - val_loss: 4314.7827\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4287.3291 - val_loss: 4183.6338\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4155.7603 - val_loss: 4056.0388\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4027.8022 - val_loss: 3931.0806\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3902.4802 - val_loss: 3809.6096\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3780.5901 - val_loss: 3691.0469\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3661.8950 - val_loss: 3575.4338\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3546.0427 - val_loss: 3463.2483\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3433.4565 - val_loss: 3354.3052\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3324.2361 - val_loss: 3248.1951\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3217.8928 - val_loss: 3145.5166\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3114.9250 - val_loss: 3045.8530\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3014.8601 - val_loss: 2949.3994\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2917.8872 - val_loss: 2856.1262\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2824.2046 - val_loss: 2765.7097\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2733.6047 - val_loss: 2678.1101\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2645.8459 - val_loss: 2593.7781\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2561.0415 - val_loss: 2512.8191\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2479.6841 - val_loss: 2434.2310\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2400.9922 - val_loss: 2358.5515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e8bf1f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in order to train the model, we need to convert the data to numpy\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "#setting the random seed to reproduce the results\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "#fitting the data\n",
    "model.fit(x=X_train,y=y_train,batch_size=64,epochs=100,\n",
    "          validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921a71c",
   "metadata": {
    "id": "e921a71c"
   },
   "source": [
    "After fitting the data, we can finally evaluate the model by calculating the Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d42f3b93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d42f3b93",
    "outputId": "1244304a-2689-46c3-9317-e47b1cc9d8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "Mean Squared Error (MSE): 2358.551592661997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:02.407490: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "#calculating MSE\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Mean Squared Error (MSE): {mean_squared_error(y_test,y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0Iv4B3rJnvzN",
   "metadata": {
    "id": "0Iv4B3rJnvzN"
   },
   "source": [
    "For this model, we received a MSE of approximately 2358, which is greater than the previous model's MSE. Let's see if we can improve the model's performance by creating two new models with adjustments: \n",
    "* The first model will have adjustments to the number of layers. \n",
    "* The second model will have adjustments to the number of neurons in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32174dfd",
   "metadata": {
    "id": "32174dfd"
   },
   "source": [
    "**Q6. Can you improve the model performance of Q5 by building two more models with more layers or more hidden units in each layer? Please recommend the best model from Q5 and Q6 by justifying your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1TN9zfUkdR3h",
   "metadata": {
    "id": "1TN9zfUkdR3h"
   },
   "source": [
    "As we stated, the first model will have a different number of layers. Instead of two layers like our original model had, this model will contain ten layers. The first nine layers will each have 6 neurons, and the last layer will only have 1 neuron because this is a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Zk-20VJ42jvV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk-20VJ42jvV",
    "outputId": "2ac2abca-7bbf-4c9a-f80f-cb73b1302c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:02.773860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 18ms/step - loss: 15640.6982 - val_loss: 15527.0664\n",
      "Epoch 2/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 15582.5791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:03.297423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 8ms/step - loss: 15609.5371 - val_loss: 15488.9102\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15561.3623 - val_loss: 15426.5889\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15477.8096 - val_loss: 15312.9746\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15314.6865 - val_loss: 15077.3467\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14955.3311 - val_loss: 14538.4170\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14128.5449 - val_loss: 13304.5752\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 12272.7324 - val_loss: 10633.4395\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8552.4346 - val_loss: 5787.1929\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3223.5815 - val_loss: 973.3898\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 633.2981 - val_loss: 641.1863\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 548.1185 - val_loss: 531.4590\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 498.2288 - val_loss: 503.3715\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 472.2621 - val_loss: 480.8141\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 449.8830 - val_loss: 460.5382\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 429.8841 - val_loss: 438.5844\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 411.2191 - val_loss: 419.3375\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 392.1492 - val_loss: 400.9798\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 374.6279 - val_loss: 383.8082\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 359.1496 - val_loss: 367.1343\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 343.0294 - val_loss: 351.3947\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 327.5741 - val_loss: 336.2350\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 312.8145 - val_loss: 322.1567\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 300.2704 - val_loss: 307.9337\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 286.9184 - val_loss: 294.6949\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 273.6956 - val_loss: 282.2652\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 261.9707 - val_loss: 270.1246\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 250.4406 - val_loss: 258.3824\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 239.8869 - val_loss: 247.1494\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 229.1004 - val_loss: 236.4416\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 218.8631 - val_loss: 225.9246\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 208.7709 - val_loss: 216.0433\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 200.5145 - val_loss: 206.4770\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 190.9274 - val_loss: 197.1481\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 182.0397 - val_loss: 188.4060\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 174.1555 - val_loss: 179.8553\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 166.4771 - val_loss: 171.9111\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 158.6289 - val_loss: 164.2418\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 152.4968 - val_loss: 158.6183\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 144.5694 - val_loss: 150.0131\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 138.4451 - val_loss: 143.3447\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 132.2352 - val_loss: 137.9985\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 126.4144 - val_loss: 131.1241\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 120.1462 - val_loss: 126.3962\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 115.3544 - val_loss: 119.8730\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 110.8245 - val_loss: 114.9071\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 105.1836 - val_loss: 110.1679\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 100.9824 - val_loss: 106.1676\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 97.4635 - val_loss: 101.9259\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 93.2792 - val_loss: 96.8624\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 88.7382 - val_loss: 92.9844\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 85.0788 - val_loss: 89.6655\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 81.5254 - val_loss: 86.1552\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 78.9004 - val_loss: 82.5199\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 75.7483 - val_loss: 79.7930\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 73.0817 - val_loss: 76.2975\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 69.8657 - val_loss: 74.1015\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 67.8003 - val_loss: 71.1508\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 64.8149 - val_loss: 68.6752\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 62.6810 - val_loss: 66.8034\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 60.0153 - val_loss: 63.5877\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 57.9196 - val_loss: 61.4090\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 56.3519 - val_loss: 60.2253\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 54.1988 - val_loss: 57.4821\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 52.2084 - val_loss: 56.1238\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 50.5272 - val_loss: 53.9088\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 48.9480 - val_loss: 52.3391\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.6372 - val_loss: 51.0120\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 46.4700 - val_loss: 49.3340\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 45.1858 - val_loss: 47.9741\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 43.9596 - val_loss: 46.6949\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 42.9720 - val_loss: 45.7368\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 41.8664 - val_loss: 44.4542\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 40.9883 - val_loss: 43.4789\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 40.0649 - val_loss: 43.6231\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 39.4298 - val_loss: 41.3359\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 38.2025 - val_loss: 40.3209\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 37.3895 - val_loss: 39.6096\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 36.5379 - val_loss: 38.5382\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 35.7209 - val_loss: 37.6574\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 8ms/step - loss: 35.0313 - val_loss: 37.3370\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 34.3681 - val_loss: 36.4218\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 33.3228 - val_loss: 35.4298\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 32.6744 - val_loss: 34.9206\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 31.9301 - val_loss: 34.7938\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 31.5862 - val_loss: 33.5385\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 30.7541 - val_loss: 33.1440\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 30.2415 - val_loss: 32.5805\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 29.8209 - val_loss: 32.0556\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 29.2714 - val_loss: 31.6742\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 28.8608 - val_loss: 31.1625\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 28.3833 - val_loss: 30.8385\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 28.1342 - val_loss: 30.5040\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 27.8289 - val_loss: 30.0677\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 27.2993 - val_loss: 29.8480\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 27.0445 - val_loss: 29.5155\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 26.7154 - val_loss: 29.2074\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 26.3891 - val_loss: 28.8136\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 26.3426 - val_loss: 28.5729\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 25.9011 - val_loss: 28.5550\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Mean Squared Error (MSE): 28.555030590391855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:18.683989: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#setting up model with adjustments to the number of layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #first layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #second layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #third layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #fourth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #fifth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #sixth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #seventh layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #eigth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #ninth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #tenth layer has 1 neuron\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "#fitting the data\n",
    "model.fit(x=X_train,y=y_train,batch_size=64,epochs=100,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "#calculating MSE to evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Mean Squared Error (MSE): {mean_squared_error(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rYsGsBST8wqU",
   "metadata": {
    "id": "rYsGsBST8wqU"
   },
   "source": [
    "After adjusting the number of layers, we can see that the MSE decreased from 2358 to 29. This suggests the model's performance improved. Let's see if we can improve the model's performance by adjusting the number of neurons. For our second model, we will have 60 neurons in the first layer and only 1 neuron in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1rJQ_EZkloXe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rJQ_EZkloXe",
    "outputId": "41fedd92-f825-4f19-ae9c-1d1377863c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 15604.1494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:18.897124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 8ms/step - loss: 15600.1211 - val_loss: 15462.5195\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15522.7031 - val_loss: 15378.3438\n",
      "Epoch 3/100\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 15466.4355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:19.126368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 15428.0898 - val_loss: 15271.5674\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15307.7520 - val_loss: 15136.8945\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15158.4492 - val_loss: 14968.8135\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14972.9209 - val_loss: 14762.2451\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14747.9844 - val_loss: 14519.0283\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14488.9268 - val_loss: 14245.2441\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14199.9316 - val_loss: 13941.5000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13881.6133 - val_loss: 13608.2559\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13534.0908 - val_loss: 13246.9248\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13158.8369 - val_loss: 12860.3203\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12759.5605 - val_loss: 12449.9775\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12337.6680 - val_loss: 12020.5771\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11897.7900 - val_loss: 11573.1523\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11441.8584 - val_loss: 11111.9180\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10973.0820 - val_loss: 10638.6904\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10492.5117 - val_loss: 10159.4609\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10007.4268 - val_loss: 9671.8340\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9515.9502 - val_loss: 9182.8682\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9024.0850 - val_loss: 8693.0332\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8532.0068 - val_loss: 8207.5010\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8045.5479 - val_loss: 7726.0688\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7564.3076 - val_loss: 7252.9980\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7091.9331 - val_loss: 6791.1484\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6632.1899 - val_loss: 6340.0474\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6183.9834 - val_loss: 5904.7500\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5751.9702 - val_loss: 5485.2231\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5336.6475 - val_loss: 5083.6860\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4939.7729 - val_loss: 4700.9321\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4563.0215 - val_loss: 4337.6675\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4205.7676 - val_loss: 3997.1470\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3871.0042 - val_loss: 3677.6448\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3557.5457 - val_loss: 3380.7307\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3266.4705 - val_loss: 3105.8247\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2997.8289 - val_loss: 2852.5466\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2751.0835 - val_loss: 2620.9863\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2525.6497 - val_loss: 2411.1294\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2320.6162 - val_loss: 2222.5388\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2137.4163 - val_loss: 2051.4363\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1971.7932 - val_loss: 1900.1127\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1824.5598 - val_loss: 1765.7397\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1693.6984 - val_loss: 1646.4785\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1577.1575 - val_loss: 1539.9941\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1474.4678 - val_loss: 1446.0503\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1383.4697 - val_loss: 1365.8400\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1305.6859 - val_loss: 1296.7593\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1238.2085 - val_loss: 1239.0985\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1181.7948 - val_loss: 1189.7966\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1134.0167 - val_loss: 1147.9752\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1093.8085 - val_loss: 1112.9716\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1060.1992 - val_loss: 1084.0356\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1032.3705 - val_loss: 1059.7072\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1008.2532 - val_loss: 1040.0824\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 988.7310 - val_loss: 1023.2631\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 971.6027 - val_loss: 1009.3550\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 957.9045 - val_loss: 996.3470\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 944.9526 - val_loss: 985.7287\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 934.4382 - val_loss: 976.0261\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 924.4353 - val_loss: 967.4941\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 915.8056 - val_loss: 959.3759\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 907.7809 - val_loss: 951.7235\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 900.1874 - val_loss: 944.5257\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 893.0098 - val_loss: 937.6154\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 886.1324 - val_loss: 930.9948\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 879.5720 - val_loss: 924.2771\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 873.3140 - val_loss: 917.6632\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 866.7921 - val_loss: 911.2641\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 860.5850 - val_loss: 904.7725\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 854.4186 - val_loss: 898.4587\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 848.1672 - val_loss: 892.0143\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 842.1026 - val_loss: 885.5522\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 835.9544 - val_loss: 879.0873\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 829.7982 - val_loss: 872.5046\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 823.6722 - val_loss: 865.9561\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 817.4503 - val_loss: 859.4885\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 811.3553 - val_loss: 852.8469\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 805.2389 - val_loss: 846.2260\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 798.9611 - val_loss: 839.6271\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 792.7700 - val_loss: 832.9720\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 786.5666 - val_loss: 826.3944\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 780.2109 - val_loss: 819.8427\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 774.1122 - val_loss: 813.0063\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 767.6760 - val_loss: 806.3754\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 761.4174 - val_loss: 799.5978\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 755.1213 - val_loss: 792.7857\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 748.6183 - val_loss: 786.2313\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 742.5316 - val_loss: 779.2928\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 736.0293 - val_loss: 772.4768\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 729.5961 - val_loss: 765.7560\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 723.2339 - val_loss: 758.8674\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 716.8196 - val_loss: 751.9572\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 710.3438 - val_loss: 745.1143\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 704.0220 - val_loss: 738.2325\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 697.5745 - val_loss: 731.3108\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 691.0944 - val_loss: 724.5441\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 684.6096 - val_loss: 717.6860\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 678.1742 - val_loss: 710.8320\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 671.6605 - val_loss: 703.9405\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 665.2493 - val_loss: 697.0297\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "Mean Squared Error (MSE): 697.0297515218416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:27.778668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#setting up model with adjustments to the number of neurons in the first layer\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #first layer has 60 neurons\n",
    "        layers.Dense(60, activation='relu'),\n",
    "        #second layer has 1 neuron\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "#fitting the data\n",
    "model.fit(x=X_train,y=y_train,batch_size=64,epochs=100,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "#calculating MSE to evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Mean Squared Error (MSE): {mean_squared_error(y_test,y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jf88T1ykmx4H",
   "metadata": {
    "id": "jf88T1ykmx4H"
   },
   "source": [
    "As we can see, the MSE changed to 697, which is not an improvement from the previous model (MSE = 29). From the models we created from Q5 and Q6, we recommend the model with more layers as the best model. Let's see if we can further improve that model by using a larger number of epochs. For the new model, we will increase the number of epochs from 100 to 200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3896e",
   "metadata": {
    "id": "c0e3896e"
   },
   "source": [
    "**Q7. Can you improve the best model in Q6 by training the model for longer using a larger epochs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "P4AhDjoNnDtx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4AhDjoNnDtx",
    "outputId": "72cbc4ad-2926-4d37-9cc1-349e9b675ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 8/19 [===========>..................] - ETA: 0s - loss: 15630.1816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:28.159245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 16ms/step - loss: 15641.7920 - val_loss: 15530.2617\n",
      "Epoch 2/200\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 15588.5459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:28.493923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 8ms/step - loss: 15615.8877 - val_loss: 15499.8730\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15576.9375 - val_loss: 15448.9727\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15504.2207 - val_loss: 15344.6074\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15341.2207 - val_loss: 15093.0791\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14925.3389 - val_loss: 14422.6904\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 13805.9961 - val_loss: 12648.6846\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 11008.6611 - val_loss: 8533.0684\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5574.8340 - val_loss: 2328.8940\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1169.9672 - val_loss: 1024.2793\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 863.5929 - val_loss: 813.1226\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 741.8815 - val_loss: 750.5823\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 685.2024 - val_loss: 702.4996\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 639.4614 - val_loss: 657.9642\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 596.7991 - val_loss: 615.9247\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 556.0165 - val_loss: 574.2238\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 517.8586 - val_loss: 535.2246\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 480.5016 - val_loss: 497.4534\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 444.9049 - val_loss: 462.2488\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 412.2603 - val_loss: 428.0695\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 380.4330 - val_loss: 395.8517\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 350.3961 - val_loss: 365.2804\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 321.4962 - val_loss: 336.6815\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 296.3891 - val_loss: 309.0371\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 271.0522 - val_loss: 283.7307\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 247.0251 - val_loss: 259.9676\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 225.4010 - val_loss: 237.8453\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 205.0384 - val_loss: 217.0961\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 186.5299 - val_loss: 198.1042\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 169.6404 - val_loss: 180.3162\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 153.8445 - val_loss: 164.3986\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 139.4698 - val_loss: 149.2709\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 127.2844 - val_loss: 136.1353\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 115.0802 - val_loss: 123.9042\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 104.6543 - val_loss: 113.2769\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 95.6161 - val_loss: 103.1070\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 87.1708 - val_loss: 94.4208\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 79.8549 - val_loss: 86.7373\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 73.3245 - val_loss: 80.0754\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 67.1293 - val_loss: 73.3461\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 62.3570 - val_loss: 67.8982\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 57.9242 - val_loss: 63.9112\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 53.8544 - val_loss: 58.8223\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 49.9607 - val_loss: 55.6680\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 47.2534 - val_loss: 51.8818\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 44.7728 - val_loss: 49.1696\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 42.1954 - val_loss: 46.8078\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 40.2512 - val_loss: 44.6957\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 38.7036 - val_loss: 43.0837\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 37.1860 - val_loss: 41.1342\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 35.5939 - val_loss: 39.6717\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 34.4355 - val_loss: 38.6878\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 33.2594 - val_loss: 37.5745\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 32.5416 - val_loss: 36.3473\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 31.6681 - val_loss: 35.6371\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 31.0621 - val_loss: 34.6223\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 30.1761 - val_loss: 34.0819\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 29.7004 - val_loss: 33.3523\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 28.9964 - val_loss: 32.7678\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 28.5389 - val_loss: 32.2997\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 28.0230 - val_loss: 31.7732\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 27.6302 - val_loss: 31.2670\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 27.3942 - val_loss: 30.9805\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 26.8252 - val_loss: 30.5100\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 26.4667 - val_loss: 30.1658\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 26.1467 - val_loss: 29.7713\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 25.8483 - val_loss: 29.4953\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 25.6051 - val_loss: 29.1581\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 25.3536 - val_loss: 28.9011\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 25.1095 - val_loss: 28.6766\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.8124 - val_loss: 28.3914\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.5605 - val_loss: 28.1919\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.3238 - val_loss: 27.9191\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.1511 - val_loss: 27.6460\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.0962 - val_loss: 28.0022\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.9846 - val_loss: 27.2997\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.6018 - val_loss: 27.1120\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.3882 - val_loss: 26.9514\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.3604 - val_loss: 26.6640\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 23.1428 - val_loss: 26.4487\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 9ms/step - loss: 23.0702 - val_loss: 26.4031\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.9176 - val_loss: 26.4988\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.8512 - val_loss: 26.0155\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.5996 - val_loss: 25.8392\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.3846 - val_loss: 26.0859\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 22.8870 - val_loss: 25.4930\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.3503 - val_loss: 25.4050\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.1293 - val_loss: 25.2401\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 22.1096 - val_loss: 25.1474\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.9168 - val_loss: 25.0976\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 21.8004 - val_loss: 24.8169\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.6619 - val_loss: 24.7132\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.6758 - val_loss: 24.8911\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.6419 - val_loss: 24.5094\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.3904 - val_loss: 24.5098\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.3982 - val_loss: 24.4611\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.2929 - val_loss: 24.2335\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.1542 - val_loss: 24.1851\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.1920 - val_loss: 24.0464\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.0522 - val_loss: 23.9775\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 21.0058 - val_loss: 23.8376\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.0418 - val_loss: 23.7593\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.8339 - val_loss: 23.7198\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.8848 - val_loss: 23.7748\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.8119 - val_loss: 23.5602\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.6766 - val_loss: 23.5246\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.6224 - val_loss: 23.6850\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.5679 - val_loss: 23.3963\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.8536 - val_loss: 23.3047\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4873 - val_loss: 23.2799\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4254 - val_loss: 23.3087\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.5197 - val_loss: 23.2739\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4006 - val_loss: 23.4534\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.5288 - val_loss: 23.5576\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.3794 - val_loss: 23.1454\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.2439 - val_loss: 23.0048\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.5597 - val_loss: 23.1419\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.3653 - val_loss: 22.9716\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.2346 - val_loss: 22.8919\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.1770 - val_loss: 23.1763\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.1106 - val_loss: 22.8985\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.0189 - val_loss: 23.0873\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.3869 - val_loss: 23.0005\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4356 - val_loss: 22.7716\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9782 - val_loss: 22.7599\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.8908 - val_loss: 22.5311\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.8370 - val_loss: 22.5338\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9899 - val_loss: 22.5815\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.1331 - val_loss: 22.5356\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.0052 - val_loss: 22.3862\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.6764 - val_loss: 22.3837\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.8217 - val_loss: 22.6909\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.7404 - val_loss: 22.5088\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.5740 - val_loss: 22.2217\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.7623 - val_loss: 22.1911\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.6622 - val_loss: 22.4936\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.4969 - val_loss: 22.1958\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.1601 - val_loss: 22.9323\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.7638 - val_loss: 22.5864\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.5289 - val_loss: 22.3534\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.7407 - val_loss: 22.6210\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.5255 - val_loss: 22.8409\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.3624 - val_loss: 22.0071\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.4775 - val_loss: 22.1906\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.3840 - val_loss: 22.4305\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.5478 - val_loss: 21.9466\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.1692 - val_loss: 22.0147\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.2792 - val_loss: 21.8348\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.5989 - val_loss: 21.8850\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.1797 - val_loss: 22.0202\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.4537 - val_loss: 21.9644\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.7520 - val_loss: 22.0213\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.2293 - val_loss: 21.7522\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.1048 - val_loss: 21.6676\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.1367 - val_loss: 22.2219\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.3209 - val_loss: 21.7696\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.1411 - val_loss: 21.6893\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.0316 - val_loss: 21.8557\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.9825 - val_loss: 21.5638\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.1811 - val_loss: 21.5091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.0173 - val_loss: 22.0107\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.8728 - val_loss: 21.9938\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.9472 - val_loss: 23.0511\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.5170 - val_loss: 22.2659\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.0306 - val_loss: 21.4513\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.7404 - val_loss: 21.3964\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 18.8093 - val_loss: 21.4957\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.8555 - val_loss: 21.5502\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.8274 - val_loss: 21.3336\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6149 - val_loss: 21.7053\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.8818 - val_loss: 21.2403\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.7335 - val_loss: 21.2979\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.9457 - val_loss: 21.1906\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6105 - val_loss: 21.2251\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.9779 - val_loss: 21.8697\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.9702 - val_loss: 21.1935\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.5281 - val_loss: 21.1721\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.5569 - val_loss: 21.1446\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.5641 - val_loss: 21.2444\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6572 - val_loss: 21.7430\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6950 - val_loss: 21.8466\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.7850 - val_loss: 21.0849\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 18.5958 - val_loss: 21.0663\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 18.7569 - val_loss: 20.9828\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.3976 - val_loss: 20.9683\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.3687 - val_loss: 20.9174\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.3377 - val_loss: 21.4470\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.4803 - val_loss: 21.4784\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6478 - val_loss: 21.1409\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6454 - val_loss: 20.8328\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.7356 - val_loss: 21.9070\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.2903 - val_loss: 20.8102\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.2015 - val_loss: 21.1310\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.2852 - val_loss: 20.9321\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 18.3190 - val_loss: 20.6869\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.1462 - val_loss: 20.7238\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.2362 - val_loss: 20.6746\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.2635 - val_loss: 20.6471\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.2227 - val_loss: 20.7370\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.1042 - val_loss: 20.6272\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Mean Squared Error (MSE): 20.62719395843288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:58.726011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#setting up model with adjustments to the number of epochs\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #first layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #second layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #third layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #fourth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #fifth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #sixth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #seventh layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #eigth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #ninth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #tenth layer has 1 neuron\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "#fitting the data\n",
    "model.fit(x=X_train,y=y_train,batch_size=64,epochs=200,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "#calculating MSE to evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Mean Squared Error (MSE): {mean_squared_error(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sLDqRh_Dn-7D",
   "metadata": {
    "id": "sLDqRh_Dn-7D"
   },
   "source": [
    "After increasing the number of epochs to 200, we received a MSE of 21, which means we were successful in improving the best model from Q6. Let's see if using a different optimizer will give us better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbd8a1",
   "metadata": {
    "id": "2acbd8a1"
   },
   "source": [
    "**Q8 Can you improve the best model in Q6 by using different optimizer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rPs45Tqh2iD6",
   "metadata": {
    "id": "rPs45Tqh2iD6"
   },
   "source": [
    "So far, we have used Adam for algorithm optimization; but for this model, we will use SGD. Both optimizers have different strengths and weaknesses. There are many articles that discuss this: [Deep Learning Optimizers: SGD with momentum, Adagrad, Adadelta, Adam optimizer](https://towardsdatascience.com/deep-learning-optimizers-436171c9e23f),\n",
    "[A 2021 Guide to improving CNNs-Optimizers: Adam vs SGD](https://medium.com/geekculture/a-2021-guide-to-improving-cnns-optimizers-adam-vs-sgd-495848ac6008), [An overview of gradient descent optimization algorithms](https://www.ruder.io/optimizing-gradient-descent/#adam). We will not go into full detail, but we will see if changing optimizers can improve the best model from Q6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "OGxCTcDao0AZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGxCTcDao0AZ",
    "outputId": "3a45fc40-f6a4-45c1-992b-dcbd13fe514b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/19 [>.............................] - ETA: 6s - loss: 15961.4453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:59.015247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 18ms/step - loss: 40704897024.0000 - val_loss: 159104640.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 113759424.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:59.438212: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step - loss: 113759424.0000 - val_loss: 73834640.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 52793120.0000 - val_loss: 34263612.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 24500198.0000 - val_loss: 15899915.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 11369971.0000 - val_loss: 7378094.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 5276555.0000 - val_loss: 3423574.7500\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2448769.7500 - val_loss: 1588507.1250\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1136448.2500 - val_loss: 737004.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 527430.8750 - val_loss: 341897.4375\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 244793.0156 - val_loss: 158596.7344\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 113631.7266 - val_loss: 73553.1250\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52755.7891 - val_loss: 34112.6602\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 24507.7227 - val_loss: 15824.1025\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 11399.5088 - val_loss: 7350.3770\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 5317.0674 - val_loss: 3421.2195\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2492.0801 - val_loss: 1603.8600\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1181.5671 - val_loss: 762.9922\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 573.4235 - val_loss: 374.9191\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 291.1624 - val_loss: 197.1212\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 160.4121 - val_loss: 115.0835\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 99.6120 - val_loss: 77.9644\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 71.5066 - val_loss: 61.2963\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 58.5113 - val_loss: 53.8315\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 52.4443 - val_loss: 50.6188\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 49.6569 - val_loss: 49.3136\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 48.3924 - val_loss: 48.8037\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.7877 - val_loss: 48.6363\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.5140 - val_loss: 48.6058\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.3871 - val_loss: 48.6277\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.3240 - val_loss: 48.6623\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2979 - val_loss: 48.6800\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2968 - val_loss: 48.7027\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2885 - val_loss: 48.7146\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2789 - val_loss: 48.7311\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2731 - val_loss: 48.7378\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2771 - val_loss: 48.7408\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2798 - val_loss: 48.7467\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2718 - val_loss: 48.7598\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2810 - val_loss: 48.7696\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2761 - val_loss: 48.7590\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2750 - val_loss: 48.7487\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2747 - val_loss: 48.7562\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2757 - val_loss: 48.7624\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2798 - val_loss: 48.7697\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2787 - val_loss: 48.7600\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2732 - val_loss: 48.7528\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2838 - val_loss: 48.7530\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2835 - val_loss: 48.7526\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2805 - val_loss: 48.7671\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2735 - val_loss: 48.7757\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 47.2834 - val_loss: 48.7700\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2766 - val_loss: 48.7685\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2727 - val_loss: 48.7598\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2810 - val_loss: 48.7553\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2802 - val_loss: 48.7572\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2795 - val_loss: 48.7582\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2815 - val_loss: 48.7522\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2799 - val_loss: 48.7466\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2801 - val_loss: 48.7578\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2733 - val_loss: 48.7632\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2757 - val_loss: 48.7720\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2814 - val_loss: 48.7673\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2785 - val_loss: 48.7623\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2739 - val_loss: 48.7630\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2762 - val_loss: 48.7668\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2846 - val_loss: 48.7611\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2740 - val_loss: 48.7569\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2727 - val_loss: 48.7637\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2860 - val_loss: 48.7630\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2845 - val_loss: 48.7606\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2855 - val_loss: 48.7683\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 47.2859 - val_loss: 48.7759\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 47.2724 - val_loss: 48.7565\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 47.2780 - val_loss: 48.7547\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2842 - val_loss: 48.7505\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2799 - val_loss: 48.7517\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 47.2718 - val_loss: 48.7511\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2754 - val_loss: 48.7558\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2755 - val_loss: 48.7574\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2776 - val_loss: 48.7640\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2863 - val_loss: 48.7620\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 47.2791 - val_loss: 48.7586\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2814 - val_loss: 48.7685\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2760 - val_loss: 48.7649\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2793 - val_loss: 48.7769\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2794 - val_loss: 48.7704\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2786 - val_loss: 48.7741\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2761 - val_loss: 48.7678\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2789 - val_loss: 48.7673\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2721 - val_loss: 48.7676\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2789 - val_loss: 48.7645\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2780 - val_loss: 48.7584\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2732 - val_loss: 48.7546\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2791 - val_loss: 48.7581\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2757 - val_loss: 48.7544\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2769 - val_loss: 48.7513\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2875 - val_loss: 48.7394\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2843 - val_loss: 48.7567\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2781 - val_loss: 48.7564\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2727 - val_loss: 48.7498\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Mean Squared Error (MSE): 48.74984628482549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:02:13.684736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#setting up model with an adjustment to the type of optimizer\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #first layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #second layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #third layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #fourth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #fifth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #sixth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #seventh layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #eigth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #ninth layer has 6 neurons\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        #tenth layer has 1 neuron\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='SGD',loss='mse')\n",
    "\n",
    "#fitting the data\n",
    "model.fit(x=X_train,y=y_train,batch_size=64,epochs=100,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "#calculating MSE to evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Mean Squared Error (MSE): {mean_squared_error(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276x80qDh0MO",
   "metadata": {
    "id": "276x80qDh0MO"
   },
   "source": [
    "After changing the optimizer, the MSE changed to 49. When we compare this adjusted model to the best model from Q6, we can see that changing optimizers did not improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jXhbKp8wfqwM",
   "metadata": {
    "id": "jXhbKp8wfqwM"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YcOA2_9wfuJG",
   "metadata": {
    "id": "YcOA2_9wfuJG"
   },
   "source": [
    "From the models we created, we have the following MSE (ranked in increasing order):\n",
    "* Fourth Tensor Model (Q7 - Increased Layers & Epochs): 21\n",
    "* Scikit-learn Model (Q3): 25\n",
    "* Second Tensor Model (Q6 - Increased Layers): 29\n",
    "* Fifth Tensor Model (Q8 - Increased Layers & Changed Optimizer): 49\n",
    "* Third Tensor Model (Q6 - Increased Neurons): 697\n",
    "* First Tensor Model (Q5): 2358\n",
    "\n",
    "Out of all of the models we created, the model's performance was the best when we increased the number of layers and neurons because it had the lowest MSE. While MSE is a way we can evaluate models, we would like to investigate more questions in the future (e.g., Are any of these models under-fitting/over-fitting the data?) before we recommend a model to NASA."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jXhbKp8wfqwM"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
